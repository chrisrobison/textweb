# TextWeb LLM Configuration
# Copy this to .env and fill in your values

# Base URL for any OpenAI-compatible API
# Default: http://localhost:1234/v1 (LM Studio)
# Examples:
#   https://api.openai.com/v1
#   https://api.anthropic.com/v1
#   http://localhost:11434/v1 (Ollama)
TEXTWEB_LLM_URL=http://localhost:1234/v1

# API key (optional for local LLMs like LM Studio/Ollama)
TEXTWEB_LLM_API_KEY=

# Model name
TEXTWEB_LLM_MODEL=google/gemma-3-4b

# Max tokens for responses (default: 200)
TEXTWEB_LLM_MAX_TOKENS=200

# Temperature (default: 0.7)
TEXTWEB_LLM_TEMPERATURE=0.7

# Request timeout in milliseconds (default: 60000)
TEXTWEB_LLM_TIMEOUT=60000
